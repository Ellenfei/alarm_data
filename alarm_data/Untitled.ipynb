{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from alarm_data_type import alarm_dict\n",
    "print(alarm_dict.level['紧急'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed40102438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.Series(np.random.randn(1000), index=np.arange(1000))\n",
    "data.cumsum()\n",
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from alarm_data_type import alarm_dict\n",
    "\n",
    "filename = 'raw_data.xls'\n",
    "table = pd.read_excel(filename, sheet_name=0, header=0)\n",
    "datas = []\n",
    "for i in range(len(table)):\n",
    "    data = []\n",
    "    data.append(alarm_dict.level[table.iloc[i].values[0]])\n",
    "    data.append(alarm_dict.event[table.iloc[i].values[1]])\n",
    "    data.append(alarm_dict.alarm_source[table.iloc[i].values[2]])\n",
    "    data.append(alarm_dict.location[table.iloc[i].values[3]])\n",
    "    data.append(alarm_dict.occur_time[table.iloc[i].values[4]])\n",
    "#     print(data)\n",
    "    datas.append(data)\n",
    "# print(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125\n"
     ]
    }
   ],
   "source": [
    "print(len(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.69887422]\n",
      "  [ 0.34230285]\n",
      "  [ 0.22699425]\n",
      "  [ 0.77393578]\n",
      "  [ 0.74112258]]\n",
      "\n",
      " [[ 0.43438026]\n",
      "  [ 0.13411872]\n",
      "  [ 0.80636242]\n",
      "  [ 0.06361837]\n",
      "  [ 0.17906289]]]\n",
      "conv1d: Tensor(\"conv1d_21/Squeeze:0\", shape=(2, 5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "input_data = tf.Variable(np.random.rand(2,5,1), dtype=np.float32)\n",
    "print(np.random.rand(2,5,1))\n",
    "filter_data = tf.Variable(np.random.rand(2,1,2), dtype=np.float32)\n",
    "y = tf.nn.conv1d(input_data, filter_data, stride=1, padding='SAME')\n",
    "print('conv1d:', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  2]\n",
      "  [  6]\n",
      "  [ 31]\n",
      "  [133]\n",
      "  [640]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 4 but is rank 3 for 'conv1d_72/Conv2D' (op: 'Conv2D') with input shapes: [1,1,1], [1,2,1,10].",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 4 but is rank 3 for 'conv1d_72/Conv2D' (op: 'Conv2D') with input shapes: [1,1,1], [1,2,1,10].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-2a9925dfceae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfilter_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_datas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv1d:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m   2011\u001b[0m     result = gen_nn_ops.conv2d(value, filters, strides, padding,\n\u001b[1;32m   2012\u001b[0m                                \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2013\u001b[0;31m                                data_format=data_format)\n\u001b[0m\u001b[1;32m   2014\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspatial_start_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m    395\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    398\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 4 but is rank 3 for 'conv1d_72/Conv2D' (op: 'Conv2D') with input shapes: [1,1,1], [1,2,1,10]."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import data_process\n",
    "\n",
    "# print(data_process.datas)\n",
    "input_data = data_process.data\n",
    "# print(np.array(input_data).shape)\n",
    "input_data1=np.resize(input_data, (1, 5, 1))\n",
    "# input1 = input_data1[0:1, :]\n",
    "print(input_data1)\n",
    "# print(np.array(input_data).shape)\n",
    "\n",
    "input_datas = tf.cast(input1, tf.float32) \n",
    "# print(input_datas.shape)\n",
    "\n",
    "filter_data = tf.Variable(np.random.rand( 2, 1, 10), dtype=np.float32)\n",
    "y = tf.nn.conv1d(input_datas, filter_data, stride=1, padding='SAME')\n",
    "h = tf.nn.relu(y)\n",
    "print('conv1d:', h)\n",
    "filter2 = tf.Variable(np.random.rand( 2, 10, 6), dtype=np.float32)\n",
    "y2 = tf.nn.conv1d(h, filter2, stride=1, padding='SAME')\n",
    "h2 = tf.nn.relu(y2)\n",
    "print('conv1d:', h2)\n",
    "w = tf.Variable(np.random.rand(3 *6, 10), dtype=np.float32)\n",
    "h3 = tf.nn.relu(tf.matmul(h2, w) )\n",
    "print(h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [2, 34], [3, 45]]\n",
      "(3, 2)\n",
      "[[[ 1]\n",
      "  [ 2]]\n",
      "\n",
      " [[ 2]\n",
      "  [34]]\n",
      "\n",
      " [[ 3]\n",
      "  [45]]]\n",
      "(3, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "a = [[1,2],[2,34],[3,45]]\n",
    "print(a)\n",
    "print(np.array(a).shape)\n",
    "b=np.resize(a,(3,2,1))\n",
    "print(b)\n",
    "print(np.array(b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78339257,  0.66187312])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-107-6fb51ac8c064>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-107-6fb51ac8c064>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    input1 = input_data1([0:1, :])\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24722061]\n",
      " [ 0.25557071]\n",
      " [ 0.2590476 ]\n",
      " ..., \n",
      " [ 0.11420187]\n",
      " [ 0.09972201]\n",
      " [ 0.09130475]]\n",
      "step 0, training accuracy 0\n",
      "[[ 0.24722061]\n",
      " [ 0.25557071]\n",
      " [ 0.2590476 ]\n",
      " ..., \n",
      " [ 0.11420187]\n",
      " [ 0.09972201]\n",
      " [ 0.09130475]]\n",
      "[[ 0.24722061]\n",
      " [ 0.25557071]\n",
      " [ 0.2590476 ]\n",
      " ..., \n",
      " [ 0.11420187]\n",
      " [ 0.09972201]\n",
      " [ 0.09130475]]\n",
      "[[ 0.24722061]\n",
      " [ 0.25557071]\n",
      " [ 0.2590476 ]\n",
      " ..., \n",
      " [ 0.11420187]\n",
      " [ 0.09972201]\n",
      " [ 0.09130475]]\n",
      "[[ 0.24722061]\n",
      " [ 0.25557071]\n",
      " [ 0.2590476 ]\n",
      " ..., \n",
      " [ 0.11420187]\n",
      " [ 0.09972201]\n",
      " [ 0.09130475]]\n",
      "[[ 0.24722061]\n",
      " [ 0.25557071]\n",
      " [ 0.2590476 ]\n",
      " ..., \n",
      " [ 0.11420187]\n",
      " [ 0.09972201]\n",
      " [ 0.09130475]]\n",
      "[[ 0.24722061]\n",
      " [ 0.25557071]\n",
      " [ 0.2590476 ]\n",
      " ..., \n",
      " [ 0.11420187]\n",
      " [ 0.09972201]\n",
      " [ 0.09130475]]\n",
      "[[ 0.24722061]\n",
      " [ 0.25557071]\n",
      " [ 0.2590476 ]\n",
      " ..., \n",
      " [ 0.11420187]\n",
      " [ 0.09972201]\n",
      " [ 0.09130475]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e54b221c733f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mys_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mys_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import data_process\n",
    "from generateData import Utils\n",
    "\n",
    "# 定义函数\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variables(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv1d(x, W):\n",
    "    return tf.nn.conv1d(x, W, stride=1, padding='SAME')\n",
    "\n",
    "# def max_pooling_22(x):\n",
    "#     return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# 1. 数据导入\n",
    "data = data_process.datas\n",
    "# input_data1 = np.resize(input_datas, (1125, 5, 1))\n",
    "datas = tf.cast(data, tf.float32)\n",
    "# input_data = np.array(datas)\n",
    "xs = datas[:, 0:5]\n",
    "ys = datas[:, 5]\n",
    "sess = tf.InteractiveSession()\n",
    "xs_ = sess.run(xs)\n",
    "ys_ = sess.run(ys)\n",
    "\n",
    "# datas = []\n",
    "# test1 = Utils()\n",
    "# for i in range(500):\n",
    "#     datas.append(test1.generateData(False))\n",
    "# for i in range(10000):\n",
    "#     datas.append(test1.generateData(True))\n",
    "# # input_data = np.array(datas)\n",
    "# listData = []\n",
    "# for i in range(len(datas)):\n",
    "#     listData.append([datas[i].nodeS, datas[i].nodeD, datas[i].bandwidth, datas[i].delay,\n",
    "#                     datas[i].loss, datas[i].flag])\n",
    "# toMatrix = np.mat(listData)\n",
    "# # print(toMatrix)\n",
    "# xs_ = toMatrix[:, 0:5]\n",
    "# ys_ = toMatrix[:, 5]\n",
    "# sess = tf.InteractiveSession()\n",
    "\n",
    "# y_actual = tf.random_normal_initializer\n",
    "\n",
    "# 2.第一层卷积\n",
    "# 参数\n",
    "W_conv1 = weight_variable([1, 1, 10])\n",
    "b_conv1 = bias_variables([10])\n",
    "x = tf.placeholder(tf.float32, [None, 5])\n",
    "x_data = tf.reshape(x, [-1, 5, 1])\n",
    "h_conv1 = tf.nn.relu(conv1d(x_data, W_conv1) + b_conv1)\n",
    "\n",
    "# 3.第二层卷积\n",
    "W_conv2 = weight_variable([2, 10, 8])\n",
    "b_conv2 = bias_variables([8])\n",
    "# 激活函数\n",
    "h_conv2 = tf.nn.relu(conv1d(h_conv1, W_conv2) + b_conv2)\n",
    "h_conv3 = tf.reshape(h_conv2, [-1, 40])\n",
    "\n",
    "# 4.全连接层\n",
    "W_fc1 = weight_variable([40, 10])\n",
    "b_fc1 = bias_variables([10])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv3, W_fc1) + b_fc1)\n",
    "\n",
    "# 5.dropout层\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# 6.输出层\n",
    "W_fc2 = weight_variable([10, 1])\n",
    "b_fc2 = bias_variables([1])\n",
    "y_predict = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "y_ = tf.placeholder(tf.float32)\n",
    "\n",
    "# 交叉熵\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_predict))\n",
    "train_step = tf.train.GradientDescentOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_predict, 0), tf.argmax(y_, 0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train_step, feed_dict={x: xs_, y_: ys_, keep_prob : 1.0})\n",
    "    y_array = sess.run(y_predict,  feed_dict={x: xs_, y_: ys_, keep_prob : 1.0})\n",
    "    for j in range(y_array.shape[0]):\n",
    "        for k in range(y_array.shape[1]):\n",
    "            if \n",
    "#     print(sess.run(y_predict,  feed_dict={x: xs_, y_: ys_, keep_prob : 1.0}))\n",
    "\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: xs_, y_: ys_, keep_prob : 1.0})\n",
    "        \n",
    "#         print(sess.run(y_predict, feed_dict={x: xs_, y_: ys_, keep_prob : 1.0}))\n",
    "#         print(sess.run(h_conv1, feed_dict={x: xs_, y_: ys_, keep_prob : 1.0}))\n",
    "#         print(sess.run(h_conv1, feed_dict={x: xs_, y_: ys_, keep_prob : 1.0}))\n",
    "#         print(sess.run(cross_entropy))\n",
    "        print('step %d, training accuracy %g' %(i, train_accuracy))\n",
    "#     sess.run(train_step, feed_dict={x: xs_, y_: ys_, keep_prob : 1.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import data_process\n",
    "datas = data_process.datas\n",
    "# input_data1 = np.resize(input_datas, (1125, 5, 1))\n",
    "datas = tf.cast(datas, tf.float32)\n",
    "xs = datas[:, 0:5]\n",
    "ys = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.47427496  1.147385   -1.12000871  0.04385659]\n",
      " [-0.51600599  0.84535235  0.46443179  0.66040236]\n",
      " [-0.3827998  -1.0683347  -0.28260228  0.60954219]]\n",
      "[1 2 2 0]\n",
      "[0 3 3]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "a = tf.random_normal(shape=[3,4],mean=0, stddev=1, dtype=tf.float32, seed=None, name=None)\n",
    "sess=tf.InteractiveSession()\n",
    "# sess.run(tf.initiablize_all_variables())\n",
    "b=tf.argmax(input=a,axis=0)\n",
    "c=tf.argmax(input=a,axis=1)\n",
    "print(sess.run(a))\n",
    "print(sess.run(b))\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2665  0.2641  0.0962\n",
       " 0.5102  0.4046  0.7861\n",
       " 0.6606  0.0716  0.0233\n",
       " 0.2446  0.1740  0.5167\n",
       " 0.5229  0.5888  0.2931\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "# x=torch.Tensor(5,3)\n",
    "x=torch.rand(5,3)\n",
    "x\n",
    "# x.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "x = Variable(torch.ones(2,2), requires_grad=True)\n",
    "# x.creator\n",
    "y=x+2\n",
    "# Variable(y).creator\n",
    "\n",
    "# y.creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 27\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=y*y*3\n",
    "out=z.mean()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.5000  4.5000\n",
       " 4.5000  4.5000\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-3.1782\n",
       " 3.6398\n",
       "-0.2337\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(3)\n",
    "x=Variable(x,requires_grad=True)\n",
    "y=x*2\n",
    "y\n",
    "y.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input--->conv2d--->relu--->maxpool2d--->conv2d--->relu--->maxpool2d--->view--->linear--->relu--->linear---MSEloss--->loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "torch.Size([1, 400])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "conv1 = nn.Conv2d(1, 6, 5)\n",
    "conv2=nn.Conv2d(6,16,5)\n",
    "fc1=nn.Linear(400, 120)\n",
    "fc2=nn.Linear(120,10)\n",
    "x = torch.autograd.Variable(torch.Tensor(1, 1, 32, 32))\n",
    "y = conv1(x)\n",
    "y= F.max_pool2d(F.relu(y),2)\n",
    "y=conv2(y)\n",
    "y=F.max_pool2d(F.relu(y),2)\n",
    "s=y.size()[1:]\n",
    "j=1\n",
    "for i in s:\n",
    "    j *= i\n",
    "print(j)\n",
    "y=y.view(-1,j)\n",
    "print(y.size())\n",
    "y=fc1(y)\n",
    "y=F.relu(y)\n",
    "y=fc2(F.relu(y))\n",
    "print(y.size())\n",
    "# print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d (1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d (6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120)\n",
      "  (fc2): Linear(in_features=120, out_features=84)\n",
      "  (fc3): Linear(in_features=84, out_features=10)\n",
      ")\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 不包括激活函数\n",
    "        self.conv1=nn.Conv2d(1, 6, 5)  # 1---输入信号的通道  6---卷积产生的通道  5---卷积核尺寸(5*5)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        # 三个全连接层\n",
    "        self.fc1=nn.Linear(16*5*5, 120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # Nx1x32x32  --> \n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x=x.view(-1,self.num_flat_features(x))\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "#     num_flat_features(x)：计算张量x的总特征量，如x是4*2*2的张量，那么它的特征总量就是16\n",
    "    def num_flat_features(self,x):\n",
    "        size=x.size()[1:]  # pytorch只接受批输入，[1:]把注意力放在3维上面\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "net=Net()\n",
    "net\n",
    "\n",
    "# 训练参数的数量\n",
    "print(net)\n",
    "params=list(net.parameters())\n",
    "# print(params)\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.1235 -0.0281  0.0672  0.0616  0.0315  0.0654  0.0246  0.0878  0.0743 -0.0531\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=Variable(torch.randn(1,1,32,32)) # （NCHW）\n",
    "input\n",
    "out=net(input)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/template/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 38.0893\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=Variable(torch.range(1,10))\n",
    "criterion=nn.MSELoss()\n",
    "loss=criterion(out, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  6.6139\n",
      " -9.2844\n",
      " -2.5006\n",
      "  7.4986\n",
      " -0.6702\n",
      "  4.7689\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad() # 归零操作\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward(retain_graph=True)\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2d in module torch.nn.modules.conv:\n",
      "\n",
      "class Conv2d(_ConvNd)\n",
      " |  Applies a 2D convolution over an input signal composed of several input\n",
      " |  planes.\n",
      " |  \n",
      " |  In the simplest case, the output value of the layer with input size\n",
      " |  :math:`(N, C_{in}, H, W)` and output :math:`(N, C_{out}, H_{out}, W_{out})`\n",
      " |  can be precisely described as:\n",
      " |  \n",
      " |  .. math::\n",
      " |  \n",
      " |      \\begin{array}{ll}\n",
      " |      out(N_i, C_{out_j})  = bias(C_{out_j})\n",
      " |                     + \\sum_{{k}=0}^{C_{in}-1} weight(C_{out_j}, k)  \\star input(N_i, k)\n",
      " |      \\end{array}\n",
      " |  \n",
      " |  where :math:`\\star` is the valid 2D `cross-correlation`_ operator\n",
      " |  \n",
      " |  | :attr:`stride` controls the stride for the cross-correlation, a single\n",
      " |    number or a tuple.\n",
      " |  | :attr:`padding` controls the amount of implicit zero-paddings on both\n",
      " |  |  sides for :attr:`padding` number of points for each dimension.\n",
      " |  | :attr:`dilation` controls the spacing between the kernel points; also\n",
      " |    known as the à trous algorithm. It is harder to describe, but this `link`_\n",
      " |    has a nice visualization of what :attr:`dilation` does.\n",
      " |  | :attr:`groups` controls the connections between inputs and outputs.\n",
      " |    `in_channels` and `out_channels` must both be divisible by `groups`.\n",
      " |  |       At groups=1, all inputs are convolved to all outputs.\n",
      " |  |       At groups=2, the operation becomes equivalent to having two conv\n",
      " |               layers side by side, each seeing half the input channels,\n",
      " |               and producing half the output channels, and both subsequently\n",
      " |               concatenated.\n",
      " |          At groups=`in_channels`, each input channel is convolved with its\n",
      " |               own set of filters (of size `out_channels // in_channels`).\n",
      " |  \n",
      " |  The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
      " |  \n",
      " |      - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
      " |      - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
      " |        and the second `int` for the width dimension\n",
      " |  \n",
      " |  .. note::\n",
      " |  \n",
      " |       Depending of the size of your kernel, several (of the last)\n",
      " |       columns of the input might be lost, because it is a valid `cross-correlation`_,\n",
      " |       and not a full `cross-correlation`_.\n",
      " |       It is up to the user to add proper padding.\n",
      " |  \n",
      " |  .. note::\n",
      " |  \n",
      " |       The configuration when `groups == in_channels` and `out_channels = K * in_channels`\n",
      " |       where `K` is a positive integer is termed in literature as depthwise convolution.\n",
      " |  \n",
      " |       In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`, if you want a\n",
      " |       depthwise convolution with a depthwise multiplier `K`,\n",
      " |       then you use the constructor arguments\n",
      " |       :math:`(in\\_channels=C_{in}, out\\_channels=C_{in} * K, ..., groups=C_{in})`\n",
      " |  \n",
      " |  Args:\n",
      " |      in_channels (int): Number of channels in the input image\n",
      " |      out_channels (int): Number of channels produced by the convolution\n",
      " |      kernel_size (int or tuple): Size of the convolving kernel\n",
      " |      stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
      " |      padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
      " |      dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
      " |      groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n",
      " |      bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n",
      " |      - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n",
      " |        :math:`H_{out} = floor((H_{in}  + 2 * padding[0] - dilation[0] * (kernel\\_size[0] - 1) - 1) / stride[0] + 1)`\n",
      " |        :math:`W_{out} = floor((W_{in}  + 2 * padding[1] - dilation[1] * (kernel\\_size[1] - 1) - 1) / stride[1] + 1)`\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight (Tensor): the learnable weights of the module of shape\n",
      " |                       (out_channels, in_channels, kernel_size[0], kernel_size[1])\n",
      " |      bias (Tensor):   the learnable bias of the module of shape (out_channels)\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> # With square kernels and equal stride\n",
      " |      >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
      " |      >>> # non-square kernels and unequal stride and with padding\n",
      " |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
      " |      >>> # non-square kernels and unequal stride and with padding and dilation\n",
      " |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
      " |      >>> input = autograd.Variable(torch.randn(20, 16, 50, 100))\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  .. _cross-correlation:\n",
      " |      https://en.wikipedia.org/wiki/Cross-correlation\n",
      " |  \n",
      " |  .. _link:\n",
      " |      https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2d\n",
      " |      _ConvNd\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  forward(self, input)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overriden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _ConvNd:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  reset_parameters(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          parameter (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`torch-nn-init`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.data.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>>\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear (2 -> 2)\n",
      " |          Parameter containing:\n",
      " |           1  1\n",
      " |           1  1\n",
      " |          [torch.FloatTensor of size 2x2]\n",
      " |          Linear (2 -> 2)\n",
      " |          Parameter containing:\n",
      " |           1  1\n",
      " |           1  1\n",
      " |          [torch.FloatTensor of size 2x2]\n",
      " |          Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all parameters and buffers to double datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on modules such as Dropout or BatchNorm.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all parameters and buffers to half datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True`` then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :func:`state_dict()` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): A dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool): Strictly enforce that the keys in :attr:`state_dict`\n",
      " |              match the keys returned by this module's `:func:`state_dict()`\n",
      " |              function.\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          >>>     print(idx, '->', m)\n",
      " |          0 -> Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |          1 -> Linear (2 -> 2)\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          >>>     print(idx, '->', m)\n",
      " |          0 -> ('', Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear (2 -> 2))\n",
      " |  \n",
      " |  named_parameters(self, memo=None, prefix='')\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None\n",
      " |      \n",
      " |      The hook should not modify the input or output.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None\n",
      " |      \n",
      " |      The hook should not modify the input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          parameter (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      When keep_vars is ``True``, it returns a Variable for each parameter\n",
      " |      (rather than a Tensor).\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional):\n",
      " |              if not None, the return dictionary is stored into destination.\n",
      " |              Default: None\n",
      " |          prefix (string, optional): Adds a prefix to the key (name) of every\n",
      " |              parameter and buffer in the result dictionary. Default: ''\n",
      " |          keep_vars (bool, optional): if ``True``, returns a Variable for each\n",
      " |              parameter. If ``False``, returns a Tensor for each parameter.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on modules such as Dropout or BatchNorm.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to dst_type.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.nn.Conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H_{out}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
